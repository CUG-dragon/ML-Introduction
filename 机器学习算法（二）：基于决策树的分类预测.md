
## <font color = red>å†³ç­–æ ‘</font>

#### å†³ç­–æ ‘æ˜¯ä¸€ç§å¸¸è§çš„åˆ†ç±»æ¨¡å‹ï¼Œåœ¨é‡‘èåˆ†æ§ã€åŒ»ç–—è¾…åŠ©è¯Šæ–­ç­‰è¯¸å¤šè¡Œä¸šå…·æœ‰è¾ƒä¸ºå¹¿æ³›çš„åº”ç”¨ã€‚
#### å†³ç­–æ ‘çš„æ ¸å¿ƒæ€æƒ³æ˜¯åŸºäºæ ‘ç»“æ„å¯¹æ•°æ®è¿›è¡Œåˆ’åˆ†ã€‚

#### <font color = blue>å†³ç­–æ ‘çš„ä¸»è¦ä¼˜ç‚¹ï¼š</font>

å…·æœ‰å¾ˆå¥½çš„è§£é‡Šæ€§ï¼Œæ¨¡å‹å¯ä»¥ç”Ÿæˆå¯ä»¥ç†è§£çš„è§„åˆ™ã€‚  
å¯ä»¥å‘ç°ç‰¹å¾çš„é‡è¦ç¨‹åº¦ã€‚  
æ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦è¾ƒä½ã€‚

#### <font color = blue>å†³ç­–æ ‘çš„ä¸»è¦ç¼ºç‚¹ï¼š</font>

æ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œéœ€è¦é‡‡ç”¨å‡ææŠ€æœ¯å¤„ç†ã€‚  
ä¸èƒ½å¾ˆå¥½åˆ©ç”¨è¿ç»­å‹ç‰¹å¾ã€‚  
é¢„æµ‹èƒ½åŠ›æœ‰é™ï¼Œæ— æ³•è¾¾åˆ°å…¶ä»–å¼ºç›‘ç£æ¨¡å‹æ•ˆæœã€‚  
æ–¹å·®è¾ƒé«˜ï¼Œæ•°æ®åˆ†å¸ƒçš„è½»å¾®æ”¹å˜å¾ˆå®¹æ˜“é€ æˆæ ‘ç»“æ„å®Œå…¨ä¸åŒã€‚

#### å†³ç­–æ ‘çš„åº”ç”¨ï¼š
æ¢¯åº¦æå‡æ ‘(GBDT)ï¼ŒXGBoostä»¥åŠLightGBMç­‰å…ˆè¿›çš„é›†æˆæ¨¡å‹éƒ½é‡‡ç”¨äº†å†³ç­–æ ‘ä½œä¸ºåŸºæ¨¡å‹ï¼Œåœ¨å¹¿å‘Šè®¡ç®—ã€CTRé¢„ä¼°ã€é‡‘èé£æ§ç­‰é¢†åŸŸå¤§æ”¾å¼‚å½©ã€‚  
å†³ç­–æ ‘åœ¨ä¸€äº›éœ€è¦æ˜ç¡®å¯è§£é‡Šç”šè‡³æå–åˆ†ç±»è§„åˆ™çš„åœºæ™¯ä¸­è¢«å¹¿æ³›åº”ç”¨ã€‚


### å­¦ä¹ ç›®æ ‡ï¼š
1ï¼‰äº†è§£ å†³ç­–æ ‘ çš„ç†è®ºçŸ¥è¯†  
2ï¼‰æŒæ¡ å†³ç­–æ ‘ çš„ sklearn å‡½æ•°è°ƒç”¨ä½¿ç”¨å¹¶å°†å…¶è¿ç”¨åˆ°ä¼é¹…æ•°æ®é›†é¢„æµ‹ã€‚



### ä»£ç æµç¨‹ï¼š

#### Part1 Demoå®è·µ

Step1:åº“å‡½æ•°å¯¼å…¥  
Step2:æ¨¡å‹è®­ç»ƒ  
Step3:æ•°æ®å’Œæ¨¡å‹å¯è§†åŒ–  
Step4:æ¨¡å‹é¢„æµ‹

#### Part2 åŸºäºä¼é¹…ï¼ˆpenguinsï¼‰æ•°æ®é›†çš„å†³ç­–æ ‘åˆ†ç±»å®è·µ

Step1:åº“å‡½æ•°å¯¼å…¥  
Step2:æ•°æ®è¯»å–/è½½å…¥  
Step3:æ•°æ®ä¿¡æ¯ç®€å•æŸ¥çœ‹  
Step4:å¯è§†åŒ–æè¿°  
Step5:åˆ©ç”¨ å†³ç­–æ ‘æ¨¡å‹ åœ¨äºŒåˆ†ç±»ä¸Š è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹  
Step6:åˆ©ç”¨ å†³ç­–æ ‘æ¨¡å‹ åœ¨ä¸‰åˆ†ç±»(å¤šåˆ†ç±»)ä¸Š è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹

### ç®—æ³•å®æˆ˜ï¼š
####  Demoå®è·µ

Step1: åº“å‡½æ•°å¯¼å…¥


```python
##  åŸºç¡€å‡½æ•°åº“
import numpy as np 

## å¯¼å…¥ç”»å›¾åº“
import matplotlib.pyplot as plt
import seaborn as sns

## å¯¼å…¥å†³ç­–æ ‘æ¨¡å‹å‡½æ•°
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
```

Step2: è®­ç»ƒæ¨¡å‹


```python
##Demoæ¼”ç¤ºLogisticRegressionåˆ†ç±»

## æ„é€ æ•°æ®é›†
x_features = np.array([[-1, -2], [-2, -1], [-3, -2], [1, 3], [2, 1], [3, 2]])
y_label = np.array([0, 1, 0, 1, 0, 1]) ##å®šä¹‰ä¸¤ç±»é¢œè‰²

## è°ƒç”¨å†³ç­–æ ‘å›å½’æ¨¡å‹
tree_clf = DecisionTreeClassifier()

## è°ƒç”¨å†³ç­–æ ‘æ¨¡å‹æ‹Ÿåˆæ„é€ çš„æ•°æ®é›†
tree_clf = tree_clf.fit(x_features, y_label)
```

Step3: æ•°æ®å’Œæ¨¡å‹å¯è§†åŒ–ï¼ˆéœ€è¦ç”¨åˆ°graphvizå¯è§†åŒ–åº“ï¼‰


```python
## å¯è§†åŒ–æ„é€ çš„æ•°æ®æ ·æœ¬ç‚¹
plt.figure()
plt.scatter(x_features[:,0],x_features[:,1],c = y_label, s = 50, cmap = 'viridis')
plt.title('DataSet')
plt.show()

## numpyæ•°ç»„è¡¨ç¤ºä¸­ï¼Œ[:,0]å–æ‰€æœ‰è¡Œçš„ç¬¬0åˆ—æ•°æ®ï¼Œå³-1 -2 -3 1 2 3;[:,1]å–æ‰€æœ‰è¡Œçš„ç¬¬1åˆ—æ•°æ® -2 -1 -2 3 1 2
## matplotlib.pyplot.scatter  å®šä¹‰ï¼Œ x,yæ˜¯äºŒç»´æ•°æ®ï¼Œ cæ˜¯color, sæ˜¯è§„æ¨¡size, cmapæ˜¯colormapå®ä¾‹
## viridis: é»„åˆ°è“
```


![png](output_7_0.png)


åœ¨ anaconda prompt ä¸‹ æ‰§è¡Œ pip install graphvizå‘½ä»¤ï¼Œå®‰è£…äº†0.14ç‰ˆæœ¬ã€‚
ä½†æ˜¯è¿˜æ˜¯æœ‰é—®é¢˜ï¼Ÿï¼Ÿ å¾…è§£å†³ï¼Ÿ


```python
## å¯è§†åŒ–å†³ç­–æ ‘
import graphviz
dot_data = tree.export_graphviz(tree_clf, out_file=None)
graph = graphviz.Source(dot_data)
graph.render("pengunis")
```

Step4:æ¨¡å‹é¢„æµ‹


```python
## åˆ›å»ºæ–°æ ·æœ¬
x_fearures_new1 = np.array([[0, -1]])
x_fearures_new2 = np.array([[2, 1]])

## åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šåˆ†å¸ƒåˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
y_label_new1_predict = tree_clf.predict(x_fearures_new1)
y_label_new2_predict = tree_clf.predict(x_fearures_new2)

print('The New point 1 predict class:\n',y_label_new1_predict)
print('The New point 2 predict class:\n',y_label_new2_predict)
```

    The New point 1 predict class:
     [1]
    The New point 2 predict class:
     [0]
    

## åŸºäºä¼é¹…æ•°æ®é›†çš„å†³ç­–æ ‘å®æˆ˜

åœ¨å®è·µçš„æœ€å¼€å§‹ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å¯¼å…¥ä¸€äº›åŸºç¡€çš„å‡½æ•°åº“åŒ…æ‹¬ï¼šnumpy ï¼ˆPythonè¿›è¡Œç§‘å­¦è®¡ç®—çš„åŸºç¡€è½¯ä»¶åŒ…ï¼‰ï¼Œpandasï¼ˆpandasæ˜¯ä¸€ç§å¿«é€Ÿï¼Œå¼ºå¤§ï¼Œçµæ´»ä¸”æ˜“äºä½¿ç”¨çš„å¼€æºæ•°æ®åˆ†æå’Œå¤„ç†å·¥å…·ï¼‰ï¼Œmatplotlibå’Œseabornç»˜å›¾ã€‚


```python
#ä¸‹è½½éœ€è¦ç”¨åˆ°çš„æ•°æ®é›†

# !wget https://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/6tree/penguins_raw.csv

#å·²å•ç‹¬ä¸‹è½½åˆ°ipynbåŒä¸€ä¸ªç›®å½•
```

Step1ï¼šå‡½æ•°åº“å¯¼å…¥


```python
##  åŸºç¡€å‡½æ•°åº“
import numpy as np 
import pandas as pd

## ç»˜å›¾å‡½æ•°åº“
import matplotlib.pyplot as plt
import seaborn as sns
```

æœ¬æ¬¡æˆ‘ä»¬é€‰æ‹©ä¼é¹…æ•°æ®ï¼ˆpalmerpenguinsï¼‰è¿›è¡Œæ–¹æ³•çš„å°è¯•è®­ç»ƒï¼Œè¯¥æ•°æ®é›†ä¸€å…±åŒ…å«8ä¸ªå˜é‡ï¼Œå…¶ä¸­7ä¸ªç‰¹å¾å˜é‡ï¼Œ1ä¸ªç›®æ ‡åˆ†ç±»å˜é‡ã€‚å…±æœ‰150ä¸ªæ ·æœ¬ï¼Œç›®æ ‡å˜é‡ä¸º ä¼é¹…çš„ç±»åˆ« å…¶éƒ½å±äºä¼é¹…ç±»çš„ä¸‰ä¸ªäºšå±ï¼Œåˆ†åˆ«æ˜¯(AdÃ©lie, Chinstrap and Gentoo)ã€‚åŒ…å«çš„ä¸‰ç§ç§ä¼é¹…çš„ä¸ƒä¸ªç‰¹å¾ï¼Œåˆ†åˆ«æ˜¯æ‰€åœ¨å²›å±¿ï¼Œå˜´å·´é•¿åº¦ï¼Œå˜´å·´æ·±åº¦ï¼Œè„šè¹¼é•¿åº¦ï¼Œèº«ä½“ä½“ç§¯ï¼Œæ€§åˆ«ä»¥åŠå¹´é¾„ã€‚

| å˜é‡ | æè¿° |
| -------- | -------- | 
|species   |a factor denoting penguin species   | 
|island	  |a factor denoting island in Palmer Archipelago, Antarctica   | 
|bill_length_mm   |a number denoting bill length   | 
|bill_depth_mm   |a number denoting bill depth  | 
|flipper_length_mm  |an integer denoting flipper length   | 
|body_mass_g   |an integer denoting body mass   | 
|sex   |a factor denoting penguin sex   | 
|year   |an integer denoting the study year  | 

Step2ï¼šæ•°æ®è¯»å–/è½½å…¥


```python
## æˆ‘ä»¬åˆ©ç”¨Pandasè‡ªå¸¦çš„read_csvå‡½æ•°è¯»å–å¹¶è½¬åŒ–ä¸ºDataFrameæ ¼å¼

data = pd.read_csv('./penguins_raw.csv')
```


```python
## ä¸ºäº†æ–¹ä¾¿æˆ‘ä»¬ä»…é€‰å–å››ä¸ªç®€å•çš„ç‰¹å¾ï¼Œæœ‰å…´è¶£çš„åŒå­¦å¯ä»¥ç ”ç©¶ä¸‹å…¶ä»–ç‰¹å¾çš„å«ä¹‰ä»¥åŠä½¿ç”¨æ–¹æ³•
data = data[['Species','Culmen Length (mm)','Culmen Depth (mm)',
            'Flipper Length (mm)','Body Mass (g)']]
```

Step3ï¼šæ•°æ®ä¿¡æ¯ç®€å•æŸ¥çœ‹


```python
## åˆ©ç”¨.info()æŸ¥çœ‹æ•°æ®çš„æ•´ä½“ä¿¡æ¯
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 344 entries, 0 to 343
    Data columns (total 5 columns):
    Species                344 non-null object
    Culmen Length (mm)     342 non-null float64
    Culmen Depth (mm)      342 non-null float64
    Flipper Length (mm)    342 non-null float64
    Body Mass (g)          342 non-null float64
    dtypes: float64(4), object(1)
    memory usage: 13.5+ KB
    


```python
## è¿›è¡Œç®€å•çš„æ•°æ®æŸ¥çœ‹ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ .head() å¤´éƒ¨.tail()å°¾éƒ¨
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Culmen Length (mm)</th>
      <th>Culmen Depth (mm)</th>
      <th>Flipper Length (mm)</th>
      <th>Body Mass (g)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>39.1</td>
      <td>18.7</td>
      <td>181.0</td>
      <td>3750.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>39.5</td>
      <td>17.4</td>
      <td>186.0</td>
      <td>3800.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>40.3</td>
      <td>18.0</td>
      <td>195.0</td>
      <td>3250.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>36.7</td>
      <td>19.3</td>
      <td>193.0</td>
      <td>3450.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
data = data.fillna(-1)
```


```python
data.tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Culmen Length (mm)</th>
      <th>Culmen Depth (mm)</th>
      <th>Flipper Length (mm)</th>
      <th>Body Mass (g)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>339</th>
      <td>Chinstrap penguin (Pygoscelis antarctica)</td>
      <td>55.8</td>
      <td>19.8</td>
      <td>207.0</td>
      <td>4000.0</td>
    </tr>
    <tr>
      <th>340</th>
      <td>Chinstrap penguin (Pygoscelis antarctica)</td>
      <td>43.5</td>
      <td>18.1</td>
      <td>202.0</td>
      <td>3400.0</td>
    </tr>
    <tr>
      <th>341</th>
      <td>Chinstrap penguin (Pygoscelis antarctica)</td>
      <td>49.6</td>
      <td>18.2</td>
      <td>193.0</td>
      <td>3775.0</td>
    </tr>
    <tr>
      <th>342</th>
      <td>Chinstrap penguin (Pygoscelis antarctica)</td>
      <td>50.8</td>
      <td>19.0</td>
      <td>210.0</td>
      <td>4100.0</td>
    </tr>
    <tr>
      <th>343</th>
      <td>Chinstrap penguin (Pygoscelis antarctica)</td>
      <td>50.2</td>
      <td>18.7</td>
      <td>198.0</td>
      <td>3775.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
## å…¶å¯¹åº”çš„ç±»åˆ«æ ‡ç­¾ä¸º'Adelie Penguin', 'Gentoo penguin', 'Chinstrap penguin'ä¸‰ç§ä¸åŒä¼é¹…çš„ç±»åˆ«ã€‚
data['Species'].unique()
```




    array(['Adelie Penguin (Pygoscelis adeliae)',
           'Gentoo penguin (Pygoscelis papua)',
           'Chinstrap penguin (Pygoscelis antarctica)'], dtype=object)




```python
## åˆ©ç”¨value_countså‡½æ•°æŸ¥çœ‹æ¯ä¸ªç±»åˆ«æ•°é‡
pd.Series(data['Species']).value_counts()
```




    Adelie Penguin (Pygoscelis adeliae)          152
    Gentoo penguin (Pygoscelis papua)            124
    Chinstrap penguin (Pygoscelis antarctica)     68
    Name: Species, dtype: int64




```python
## å¯¹äºç‰¹å¾è¿›è¡Œä¸€äº›ç»Ÿè®¡æè¿°
data.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Culmen Length (mm)</th>
      <th>Culmen Depth (mm)</th>
      <th>Flipper Length (mm)</th>
      <th>Body Mass (g)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>344.000000</td>
      <td>344.000000</td>
      <td>344.000000</td>
      <td>344.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>43.660756</td>
      <td>17.045640</td>
      <td>199.741279</td>
      <td>4177.319767</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.428957</td>
      <td>2.405614</td>
      <td>20.806759</td>
      <td>861.263227</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>39.200000</td>
      <td>15.500000</td>
      <td>190.000000</td>
      <td>3550.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>44.250000</td>
      <td>17.300000</td>
      <td>197.000000</td>
      <td>4025.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>48.500000</td>
      <td>18.700000</td>
      <td>213.000000</td>
      <td>4750.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>59.600000</td>
      <td>21.500000</td>
      <td>231.000000</td>
      <td>6300.000000</td>
    </tr>
  </tbody>
</table>
</div>



Step4:å¯è§†åŒ–æè¿°


```python
## ç‰¹å¾ä¸æ ‡ç­¾ç»„åˆçš„æ•£ç‚¹å¯è§†åŒ–
sns.pairplot(data=data, diag_kind='hist', hue= 'Species')
plt.show()
```


![png](output_30_0.png)


ä»ä¸Šå›¾å¯ä»¥å‘ç°ï¼Œåœ¨2Dæƒ…å†µä¸‹ä¸åŒçš„ç‰¹å¾ç»„åˆå¯¹äºä¸åŒç±»åˆ«çš„ä¼é¹…çš„æ•£ç‚¹åˆ†å¸ƒï¼Œä»¥åŠå¤§æ¦‚çš„åŒºåˆ†èƒ½åŠ›ã€‚Culmen Lenthä¸å…¶ä»–ç‰¹å¾çš„ç»„åˆæ•£ç‚¹çš„é‡åˆè¾ƒå°‘ï¼Œæ‰€ä»¥å¯¹äºæ•°æ®é›†çš„åˆ’åˆ†èƒ½åŠ›æœ€å¥½ã€‚




```python
'''ä¸ºäº†æ–¹ä¾¿æˆ‘ä»¬å°†æ ‡ç­¾è½¬åŒ–ä¸ºæ•°å­—
       'Adelie Penguin (Pygoscelis adeliae)'        ------0
       'Gentoo penguin (Pygoscelis papua)'          ------1
       'Chinstrap penguin (Pygoscelis antarctica)   ------2 '''

def trans(x):
    if x == data['Species'].unique()[0]:
        return 0
    if x == data['Species'].unique()[1]:
        return 1
    if x == data['Species'].unique()[2]:
        return 2

data['Species'] = data['Species'].apply(trans)
```


```python
for col in data.columns:
    if col != 'Species':
        sns.boxplot(x='Species', y=col, saturation=0.5, palette='pastel', data=data)
        plt.title(col)
        plt.show()
```


![png](output_33_0.png)



![png](output_33_1.png)



![png](output_33_2.png)



![png](output_33_3.png)


åˆ©ç”¨ç®±å‹å›¾æˆ‘ä»¬ä¹Ÿå¯ä»¥å¾—åˆ°ä¸åŒç±»åˆ«åœ¨ä¸åŒç‰¹å¾ä¸Šçš„åˆ†å¸ƒå·®å¼‚æƒ…å†µã€‚


```python
# é€‰å–å…¶å‰ä¸‰ä¸ªç‰¹å¾ç»˜åˆ¶ä¸‰ç»´æ•£ç‚¹å›¾
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(10,8))
ax = fig.add_subplot(111, projection='3d')

data_class0 = data[data['Species']==0].values
data_class1 = data[data['Species']==1].values
data_class2 = data[data['Species']==2].values
# 'setosa'(0), 'versicolor'(1), 'virginica'(2)
ax.scatter(data_class0[:,0], data_class0[:,1], data_class0[:,2],label=data['Species'].unique()[0])
ax.scatter(data_class1[:,0], data_class1[:,1], data_class1[:,2],label=data['Species'].unique()[1])
ax.scatter(data_class2[:,0], data_class2[:,1], data_class2[:,2],label=data['Species'].unique()[2])
plt.legend()

plt.show()
```


![png](output_35_0.png)


Step5:åˆ©ç”¨ å†³ç­–æ ‘æ¨¡å‹ åœ¨äºŒåˆ†ç±»ä¸Š è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹


```python
## ä¸ºäº†æ­£ç¡®è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œå°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œåœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯æ¨¡å‹æ€§èƒ½ã€‚
from sklearn.model_selection import train_test_split

## é€‰æ‹©å…¶ç±»åˆ«ä¸º0å’Œ1çš„æ ·æœ¬ ï¼ˆä¸åŒ…æ‹¬ç±»åˆ«ä¸º2çš„æ ·æœ¬ï¼‰
data_target_part = data[data['Species'].isin([0,1])][['Species']]
data_features_part = data[data['Species'].isin([0,1])][['Culmen Length (mm)','Culmen Depth (mm)',
            'Flipper Length (mm)','Body Mass (g)']]

## æµ‹è¯•é›†å¤§å°ä¸º20%ï¼Œ 80%/20%åˆ†
x_train, x_test, y_train, y_test = train_test_split(data_features_part, data_target_part, test_size = 0.2, random_state = 2)
```


```python
## ä»sklearnä¸­å¯¼å…¥å†³ç­–æ ‘æ¨¡å‹
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
## å®šä¹‰ å†³ç­–æ ‘æ¨¡å‹ 
clf = DecisionTreeClassifier(criterion='entropy')
# åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒå†³ç­–æ ‘æ¨¡å‹
clf.fit(x_train, y_train)
```




    DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,
                max_features=None, max_leaf_nodes=None,
                min_impurity_decrease=0.0, min_impurity_split=None,
                min_samples_leaf=1, min_samples_split=2,
                min_weight_fraction_leaf=0.0, presort=False, random_state=None,
                splitter='best')




```python
## å¯è§†åŒ–
import graphviz
dot_data = tree.export_graphviz(clf, out_file=None)
graph = graphviz.Source(dot_data)
graph.render("penguins")
```


```python
## åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šåˆ†å¸ƒåˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
train_predict = clf.predict(x_train)
test_predict = clf.predict(x_test)
from sklearn import metrics

## åˆ©ç”¨accuracyï¼ˆå‡†ç¡®åº¦ï¼‰ã€é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°ç›®å æ€»é¢„æµ‹æ ·æœ¬æ•°ç›®çš„æ¯”ä¾‹ã€‘è¯„ä¼°æ¨¡å‹æ•ˆæœ
print('The accuracy of the Logistic Regression is:',metrics.accuracy_score(y_train,train_predict))
print('The accuracy of the Logistic Regression is:',metrics.accuracy_score(y_test,test_predict))

## æŸ¥çœ‹æ··æ·†çŸ©é˜µ (é¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„å„ç±»æƒ…å†µç»Ÿè®¡çŸ©é˜µ)
confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)
print('The confusion matrix result:\n',confusion_matrix_result)

# åˆ©ç”¨çƒ­åŠ›å›¾å¯¹äºç»“æœè¿›è¡Œå¯è§†åŒ–
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix_result, annot=True, cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()
```

    The accuracy of the Logistic Regression is: 1.0
    The accuracy of the Logistic Regression is: 0.9821428571428571
    The confusion matrix result:
     [[34  0]
     [ 1 21]]
    


![png](output_40_1.png)


æˆ‘ä»¬å¯ä»¥å‘ç°å…¶å‡†ç¡®åº¦ä¸º1ï¼Œä»£è¡¨æ‰€æœ‰çš„æ ·æœ¬éƒ½é¢„æµ‹æ­£ç¡®äº†ã€‚

Step6:åˆ©ç”¨ å†³ç­–æ ‘æ¨¡å‹ åœ¨ä¸‰åˆ†ç±»(å¤šåˆ†ç±»)ä¸Š è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹


```python
## æµ‹è¯•é›†å¤§å°ä¸º20%ï¼Œ 80%/20%åˆ†
x_train, x_test, y_train, y_test = train_test_split(data[['Culmen Length (mm)','Culmen Depth (mm)',
            'Flipper Length (mm)','Body Mass (g)']], data[['Species']], test_size = 0.2, random_state = 2020)
## å®šä¹‰ å†³ç­–æ ‘æ¨¡å‹ 
clf = DecisionTreeClassifier()
# åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒå†³ç­–æ ‘æ¨¡å‹
clf.fit(x_train, y_train)
```




    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                max_features=None, max_leaf_nodes=None,
                min_impurity_decrease=0.0, min_impurity_split=None,
                min_samples_leaf=1, min_samples_split=2,
                min_weight_fraction_leaf=0.0, presort=False, random_state=None,
                splitter='best')




```python
## åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šåˆ†å¸ƒåˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
train_predict = clf.predict(x_train)
test_predict = clf.predict(x_test)

## ç”±äºå†³ç­–æ ‘æ¨¡å‹æ˜¯æ¦‚ç‡é¢„æµ‹æ¨¡å‹ï¼ˆå‰æ–‡ä»‹ç»çš„ p = p(y=1|x,\theta)ï¼‰,æ‰€æœ‰æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ predict_proba å‡½æ•°é¢„æµ‹å…¶æ¦‚ç‡
train_predict_proba = clf.predict_proba(x_train)
test_predict_proba = clf.predict_proba(x_test)

print('The test predict Probability of each class:\n',test_predict_proba)
## å…¶ä¸­ç¬¬ä¸€åˆ—ä»£è¡¨é¢„æµ‹ä¸º0ç±»çš„æ¦‚ç‡ï¼Œç¬¬äºŒåˆ—ä»£è¡¨é¢„æµ‹ä¸º1ç±»çš„æ¦‚ç‡ï¼Œç¬¬ä¸‰åˆ—ä»£è¡¨é¢„æµ‹ä¸º2ç±»çš„æ¦‚ç‡ã€‚

## åˆ©ç”¨accuracyï¼ˆå‡†ç¡®åº¦ï¼‰ã€é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°ç›®å æ€»é¢„æµ‹æ ·æœ¬æ•°ç›®çš„æ¯”ä¾‹ã€‘è¯„ä¼°æ¨¡å‹æ•ˆæœ
print('The accuracy of the Logistic Regression is:',metrics.accuracy_score(y_train,train_predict))
print('The accuracy of the Logistic Regression is:',metrics.accuracy_score(y_test,test_predict))
```

    The test predict Probability of each class:
     [[0. 0. 1.]
     [0. 1. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 0. 1.]
     [0. 0. 1.]
     [1. 0. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [0. 1. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 0. 1.]
     [1. 0. 0.]
     [0. 0. 1.]
     [1. 0. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 0. 1.]
     [0. 0. 1.]
     [0. 1. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 0. 1.]
     [0. 0. 1.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [1. 0. 0.]
     [0. 0. 1.]
     [0. 1. 0.]
     [0. 1. 0.]
     [0. 0. 1.]
     [0. 0. 1.]
     [0. 1. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [1. 0. 0.]
     [0. 1. 0.]
     [0. 1. 0.]
     [0. 0. 1.]
     [0. 0. 1.]
     [1. 0. 0.]
     [0. 1. 0.]
     [0. 0. 1.]
     [1. 0. 0.]
     [1. 0. 0.]]
    The accuracy of the Logistic Regression is: 0.9963636363636363
    The accuracy of the Logistic Regression is: 0.9710144927536232
    


```python
## æŸ¥çœ‹æ··æ·†çŸ©é˜µ
confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)
print('The confusion matrix result:\n',confusion_matrix_result)

# åˆ©ç”¨çƒ­åŠ›å›¾å¯¹äºç»“æœè¿›è¡Œå¯è§†åŒ–
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix_result, annot=True, cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()
```

    The confusion matrix result:
     [[31  0  0]
     [ 0 23  0]
     [ 1  1 13]]
    


![png](output_44_1.png)


2.4 é‡è¦çŸ¥è¯†ç‚¹  
2.4.1 å†³ç­–æ ‘æ„å»ºçš„ä¼ªä»£ç   

è¾“å…¥ï¼š è®­ç»ƒé›†D={($x_1$,$y_1$),($x_2$,$y_2$),....,($x_m$,$y_m$)};    
ç‰¹å¾é›†A={$a_1$,$a_2$,....,$a_d$}
    
è¾“å‡ºï¼š ä»¥nodeä¸ºæ ¹èŠ‚ç‚¹çš„ä¸€é¢—å†³ç­–æ ‘

è¿‡ç¨‹ï¼šå‡½æ•°TreeGenerate($D$,$A$)    
1. ç”ŸæˆèŠ‚ç‚¹node    
2. $if$ $D$ä¸­æ ·æœ¬å…¨ä¹¦å±äºåŒä¸€ç±»åˆ«$C$ $then$:    
3. ----å°†nodeæ ‡è®°ä¸º$C$ç±»å¶èŠ‚ç‚¹ï¼›$return$    
4. $if$ $A$ = ç©ºé›† OR Dä¸­æ ·æœ¬åœ¨$A$ä¸Šçš„å–å€¼ç›¸åŒ $then$:
5. ----å°†nodeæ ‡è®°ä¸ºå¶èŠ‚ç‚¹ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸º$D$ä¸­æ ·æœ¬æ•°æœ€å¤šçš„ç±»ï¼›$return$
6. ä» $A$ ä¸­é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§ $a_*$;
7. $for$ $a_*$ çš„æ¯ä¸€ä¸ªå€¼ $a_*^v$ $do$:
8. ----ä¸ºnodeç”Ÿæˆä¸€ä¸ªåˆ†æ”¯ï¼Œä»¤$D_v$è¡¨ç¤º$D$ä¸­åœ¨$a_*$ä¸Šå–å€¼ä¸º$a_*^v$çš„æ ·æœ¬å­é›†ï¼›
9. ----$if$ $D_v$ ä¸ºç©º $then$:
10. --------å°†åˆ†æ”¯èŠ‚ç‚¹æ ‡è®°ä¸ºå¶èŠ‚ç‚¹ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸º$D$ä¸­æ ·æœ¬æœ€å¤šçš„ç±»;$then$
11. ----$else$:
12. --------ä»¥ TreeGenerate($D_v$,$A$\{$a_*$})ä¸ºåˆ†æ”¯èŠ‚ç‚¹

å†³ç­–æ ‘çš„æ„å»ºè¿‡ç¨‹æ˜¯ä¸€ä¸ªé€’å½’è¿‡ç¨‹ã€‚å‡½æ•°å­˜åœ¨ä¸‰ç§è¿”å›çŠ¶æ€ï¼šï¼ˆ1ï¼‰å½“å‰èŠ‚ç‚¹åŒ…å«çš„æ ·æœ¬å…¨éƒ¨å±äºåŒä¸€ç±»åˆ«ï¼Œæ— éœ€ç»§ç»­åˆ’åˆ†ï¼›ï¼ˆ2ï¼‰å½“å‰å±æ€§é›†ä¸ºç©ºæˆ–è€…æ‰€æœ‰æ ·æœ¬åœ¨æŸä¸ªå±æ€§ä¸Šçš„å–å€¼ç›¸åŒï¼Œæ— æ³•ç»§ç»­åˆ’åˆ†ï¼›ï¼ˆ3ï¼‰å½“å‰èŠ‚ç‚¹åŒ…å«çš„æ ·æœ¬é›†åˆä¸ºç©ºï¼Œæ— æ³•åˆ’åˆ†ã€‚

2.4.2 åˆ’åˆ†é€‰æ‹©
ä»ä¸Šè¿°ä¼ªä»£ç ä¸­æˆ‘ä»¬å‘ç°ï¼Œå†³ç­–æ ‘çš„å…³é”®åœ¨äºline6.ä» ğ´ ä¸­é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§ ğ‘âˆ— ï¼Œä¸€èˆ¬æˆ‘ä»¬å¸Œæœ›å†³ç­–æ ‘æ¯æ¬¡åˆ’åˆ†èŠ‚ç‚¹ä¸­åŒ…å«çš„æ ·æœ¬å°½é‡å±äºåŒä¸€ç±»åˆ«ï¼Œä¹Ÿå°±æ˜¯èŠ‚ç‚¹çš„â€œçº¯åº¦â€æ›´é«˜ã€‚

2.4.2.1 ä¿¡æ¯å¢ç›Š
ä¿¡æ¯ç†µæ˜¯ä¸€ç§è¡¡é‡æ•°æ®æ··ä¹±ç¨‹åº¦çš„æŒ‡æ ‡ï¼Œä¿¡æ¯ç†µè¶Šå°ï¼Œåˆ™æ•°æ®çš„â€œçº¯åº¦â€è¶Šé«˜

$\operatorname{Ent}(D)=-\sum_{k=1}^{|\mathcal{Y}|} p_{k} \log _{2} p_{k}$     
å…¶ä¸­$p_k$ä»£è¡¨äº†ç¬¬$k$ç±»æ ·æœ¬åœ¨$D$ä¸­å æœ‰çš„æ¯”ä¾‹ã€‚

å‡è®¾ç¦»æ•£å±æ€§$a$æœ‰$V$ä¸ªå¯èƒ½çš„å–å€¼{$a^1$,$a^2$,....,$a^V$}ï¼Œè‹¥ä½¿ç”¨$a$å¯¹æ•°æ®é›†$D$è¿›è¡Œåˆ’åˆ†ï¼Œåˆ™äº§ç”Ÿ$D$ä¸ªåˆ†æ”¯èŠ‚ç‚¹ï¼Œè®°ä¸º$D^v$ã€‚åˆ™ä½¿ç”¨$a$å¯¹æ•°æ®é›†è¿›è¡Œåˆ’åˆ†æ‰€å¸¦æ¥çš„ä¿¡æ¯å¢ç›Šè¢«å®šä¹‰ä¸ºï¼š  

$\operatorname{Gain}(D, a)=\operatorname{Ent}(D)-\sum_{v=1}^{V} \frac{\left|D^{v}\right|}{|D|} \operatorname{Ent}\left(D^{v}\right)$  
ä¸€èˆ¬çš„ä¿¡æ¯å¢ç›Šè¶Šå¤§ï¼Œåˆ™æ„å‘³ç€ä½¿ç”¨ç‰¹å¾ ğ‘ æ¥è¿›è¡Œåˆ’åˆ†çš„æ•ˆæœè¶Šå¥½ã€‚

2.4.2.2 åŸºå°¼æŒ‡æ•°
$\begin{aligned}
\operatorname{Gini}(D) &=\sum_{k=1}^{|\mathcal{Y}|} \sum_{k^{\prime} \neq k} p_{k} p_{k^{\prime}} \\
&=1-\sum_{k=1}^{|\mathcal{Y}|} p_{k}^{2}
\end{aligned}$  
åŸºå°¼æŒ‡æ•°åæ˜ äº†ä»æ•°æ®é›† ğ· ä¸­éšæœºæŠ½å–ä¸¤ä¸ªçš„ç±»åˆ«æ ‡è®°ä¸ä¸€è‡´çš„æ¦‚ç‡ã€‚

$\operatorname{Gini}\operatorname{index}(D, a)=\sum_{v=1}^{V} \frac{\left|D^{v}\right|}{|D|} \operatorname{Gini}\left(D^{v}\right)$   
ä½¿ç”¨ç‰¹å¾ ğ‘ å¯¹æ•°æ®é›† ğ· åˆ’åˆ†çš„åŸºå°¼æŒ‡æ•°å®šä¹‰ä¸ºä¸Šã€‚

2.4.3 é‡è¦å‚æ•°
2.4.3.1 criterion
Criterionè¿™ä¸ªå‚æ•°æ­£æ˜¯ç”¨æ¥å†³å®šæ¨¡å‹ç‰¹å¾é€‰æ‹©çš„è®¡ç®—æ–¹æ³•çš„ã€‚sklearnæä¾›äº†ä¸¤ç§é€‰æ‹©ï¼š

è¾“å…¥â€entropyâ€œï¼Œä½¿ç”¨ä¿¡æ¯ç†µï¼ˆEntropyï¼‰  

è¾“å…¥â€giniâ€œï¼Œä½¿ç”¨åŸºå°¼ç³»æ•°ï¼ˆGini Impurityï¼‰  

2.4.3.2 random_state & splitter  
random_stateç”¨æ¥è®¾ç½®åˆ†æä¸­çš„éšæœºæ¨¡å¼çš„å‚æ•°ï¼Œé»˜è®¤Noneï¼Œåœ¨é«˜ç»´åº¦æ—¶éšæœºæ€§ä¼šè¡¨ç°æ›´æ˜æ˜¾ã€‚splitterä¹Ÿæ˜¯ç”¨æ¥æ§åˆ¶å†³ç­–æ ‘ä¸­çš„éšæœºé€‰é¡¹çš„ï¼Œæœ‰ä¸¤ç§è¾“å…¥å€¼ï¼Œè¾“å…¥â€best"ï¼Œå†³ç­–æ ‘åœ¨åˆ†ææ—¶è™½ç„¶éšæœºï¼Œä½†æ˜¯è¿˜æ˜¯ä¼šä¼˜å…ˆé€‰æ‹©æ›´é‡è¦çš„ç‰¹å¾è¿›è¡Œåˆ†æï¼ˆé‡è¦æ€§å¯ä»¥é€šè¿‡å±æ€§feature_importances_æŸ¥çœ‹ï¼‰ï¼Œè¾“å…¥â€œrandom"ï¼Œå†³ç­–æ ‘åœ¨åˆ†ææ—¶ä¼šæ›´åŠ éšæœºï¼Œæ ‘ä¼šå› ä¸ºå«æœ‰æ›´å¤šçš„ä¸å¿…è¦ä¿¡æ¯è€Œæ›´æ·±æ›´å¤§ï¼Œå¹¶å› è¿™äº›ä¸å¿…è¦ä¿¡æ¯è€Œé™ä½å¯¹è®­ç»ƒé›†çš„æ‹Ÿåˆã€‚  

2.4.3.3 max_depth  
é™åˆ¶æ ‘çš„æœ€å¤§æ·±åº¦ï¼Œè¶…è¿‡è®¾å®šæ·±åº¦çš„æ ‘æå…¨éƒ¨å‰ªæ‰ã€‚è¿™æ˜¯ç”¨å¾—æœ€å¹¿æ³›çš„å‰ªæå‚æ•°ï¼Œåœ¨é«˜ç»´åº¦ä½æ ·æœ¬é‡æ—¶éå¸¸æœ‰æ•ˆã€‚å†³ç­–æ ‘å¤šç”Ÿé•¿ä¸€å±‚ï¼Œå¯¹æ ·æœ¬é‡çš„éœ€æ±‚ä¼šå¢åŠ ä¸€å€ï¼Œæ‰€ä»¥é™åˆ¶æ ‘æ·±åº¦èƒ½å¤Ÿæœ‰æ•ˆåœ°é™åˆ¶è¿‡æ‹Ÿåˆã€‚  

2.4.3.4 min_samples_leaf  
min_samples_leaf é™å®šï¼Œä¸€ä¸ªèŠ‚ç‚¹åœ¨åˆ†æåçš„æ¯ä¸ªå­èŠ‚ç‚¹éƒ½å¿…é¡»åŒ…å«è‡³å°‘min_samples_leafä¸ªè®­ç»ƒæ ·æœ¬ï¼Œå¦åˆ™åˆ†æå°±ä¸ä¼šå‘ç”Ÿï¼Œæˆ–è€…ï¼Œåˆ†æä¼šæœç€æ»¡è¶³æ¯ä¸ªå­èŠ‚ç‚¹éƒ½åŒ…å«min_samples_leafä¸ªæ ·æœ¬çš„æ–¹å‘å»å‘ç”Ÿã€‚ä¸€èˆ¬æ­é…max_depthä½¿ç”¨ï¼Œåœ¨å›å½’æ ‘ä¸­æœ‰ç¥å¥‡çš„æ•ˆæœï¼Œå¯ä»¥è®©æ¨¡å‹å˜å¾—æ›´åŠ å¹³æ»‘ã€‚è¿™ä¸ªå‚æ•°çš„æ•°é‡è®¾ç½®å¾—å¤ªå°ä¼šå¼•èµ·è¿‡æ‹Ÿåˆï¼Œè®¾ç½®å¾—å¤ªå¤§å°±ä¼šé˜»æ­¢æ¨¡å‹å­¦ä¹ æ•°æ®ã€‚


```python

```
